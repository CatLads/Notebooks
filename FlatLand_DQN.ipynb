{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlatLand DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMciU+nDnz3//aOZaXZ5Q/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatLads/Notebooks/blob/main/FlatLand_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfdEAgKjB2ay",
        "outputId": "cb4fa677-1fe3-43ef-a076-e7fce1458776"
      },
      "source": [
        "!sudo apt install -y xvfb ffmpeg\n",
        "!pip install -q 'imageio==2.4.0'\n",
        "!pip install -q pyvirtualdisplay\n",
        "!pip install -q tf-agents\n",
        "!pip install -q flatland-rl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n",
            "Fetched 784 kB in 1s (1,099 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 5.6MB/s \n",
            "\u001b[?25h  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 5.9MB/s \n",
            "\u001b[?25h  Building wheel for flatland-rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crowdai-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tf-agents 0.7.1 has requirement cloudpickle>=1.3, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-agents 0.7.1 has requirement gym>=0.17.0, but you'll have gym 0.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement cloudpickle>=1.3, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxiXt5sTB9PK"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment, py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.networks import sequential \n",
        "from tf_agents.policies import random_tf_policy \n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory, time_step\n",
        "from tf_agents.specs import tensor_spec, BoundedArraySpec\n",
        "from tf_agents.utils import common \n",
        "from flatland.envs.rail_env import RailEnv\n",
        "\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400,900)).start()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZVaFvxQCBP-"
      },
      "source": [
        "num_iterations = 30000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100 # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000 # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64 # @param {type:\"integer\"}\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "log_interval = 200 # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10 # @param {type:\"integer\"}\n",
        "eval_interval = 1000 # @param {type:\"integer\"}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3l9WfEDh_Gu"
      },
      "source": [
        "Next, we're gonna try and reimplement the `Rails` env with all of the things that TensorFlow needs, like explained [here](https://www.tensorflow.org/agents/tutorials/2_environments_tutorial) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmLo4iah9z0"
      },
      "source": [
        "class FatRails(py_environment.PyEnvironment):\n",
        "    def __init__(self, width, height):\n",
        "        self.env = RailEnv(width, height)\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "    def action_spec(self):\n",
        "        return BoundedArraySpec(shape=(), dtype=np.int64, name='action', minimum=0, maximum=4)\n",
        "    def observation_spec(self):\n",
        "        return (BoundedArraySpec(shape=(3,self.width, self.height, 16), dtype=np.int32, minimum=0, maximum=1, name='observation'), BoundedArraySpec(shape=(), dtype=np.int32, minimum=0, maximum=1, name='reward')) #TODO\n",
        "    def _step(self, action):\n",
        "        step_env = self.env.step(action)\n",
        "        print(step_env[0][0].shape)\n",
        "        return time_step.transition(step_env[0][0][0], step_env[1][0])\n",
        "    def _reset(self):\n",
        "        reset = self.env.reset()\n",
        "        return time_step.restart(np.array(reset[0][0][0], dtype=np.int32))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cip9mv0Tx3D_",
        "outputId": "59b55569-f1e4-4975-d58c-352cc0c29f9d"
      },
      "source": [
        "environment = FatRails(16,16)\n",
        "environment._reset()\n",
        "utils.validate_py_environment(environment, episodes=5)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-5a9a93407164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFatRails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_py_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/environments/utils.py\u001b[0m in \u001b[0;36mvalidate_py_environment\u001b[0;34m(environment, episodes)\u001b[0m\n\u001b[1;32m     65\u001b[0m       raise ValueError(\n\u001b[1;32m     66\u001b[0m           \u001b[0;34m'Given `time_step`: %r does not match expected `time_step_spec`: %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m           (time_step, time_step_spec))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Given `time_step`: TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 1, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 1, ..., 0, 0, 0],\n        [0, 0, 1, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 1, 0, ..., 0, 1, 1],\n        ...,\n        [1, 1, 0, ..., 0, 1, 1],\n        [1, 0, 0, ..., 0, 0, 1],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 1, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [1, 1, 0, ..., 0, 1, 0],\n        ...,\n        [1, 1, 0, ..., 0, 1, 1],\n        [1, 0, 0, ..., 0, 0, 1],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       ...,\n\n       [[0, 0, 0, ..., 1, 0, 0],\n        [1, 0, 0, ..., 0, 0, 0],\n        [0, 1, 0, ..., 0, 1, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 1],\n        [1, 0, 0, ..., 0, 0, 1],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 1, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 1, 0, ..., 0, 1, 0],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)) does not match expected `time_step_spec`: TimeStep(step_type=ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'), reward=ArraySpec(shape=(), dtype=dtype('float32'), name='reward'), discount=BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0), observation=(BoundedArraySpec(shape=(3, 16, 16, 16), dtype=dtype('int32'), name='observation', minimum=0, maximum=1), BoundedArraySpec(shape=(), dtype=dtype('int32'), name='reward', minimum=0, maximum=1)))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5YV0CLwCDEo"
      },
      "source": [
        "from tf_agents.specs import BoundedArraySpec\n",
        "env = RailEnv(width=16, height=16)\n",
        "# TODO: The self.number_of_agents spec might be wrong: it is a dict, not a ndarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "22Jujtcfqx6z",
        "outputId": "d6aeb4d3-66f2-4c32-9987-a7eac02db8bb"
      },
      "source": [
        "from flatland.envs.rail_env import RailEnvActions\n",
        "env.step({0: RailEnvActions.DO_NOTHING})[1]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-40c749a10184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflatland\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrail_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRailEnvActions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRailEnvActions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDO_NOTHING\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPhBk25CrkZJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EehoB0wZDcJk"
      },
      "source": [
        "fc_layer_params = (100,50)\n",
        "\n",
        "action_tensor_spec = tensor_spec.from_spec(env.action_spec)\n",
        "num_actions = action_tensor_spec.maximum-action_tensor_spec.minimum + 1\n",
        "\n",
        "\n",
        "\n",
        "def dense_layer(num_units):\n",
        "    return tf.keras.layers.Dense(\n",
        "        num_units,\n",
        "        activation=tf.keras.activations.relu,\n",
        "        kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "            scale=2.0, mode='fan_in', distribution='truncated_normal'\n",
        "        )\n",
        "    )\n",
        "\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03\n",
        "    ),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2)\n",
        ")\n",
        "q_net = sequential.Sequential(dense_layers+[q_values_layer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lr9sjUoGMEb"
      },
      "source": [
        "env.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyKhA5YmDeXM"
      },
      "source": [
        "from tf_agents.trajectories.time_step import TimeStep\n",
        "time_step_spec = TimeStep()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}